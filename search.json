[{"title":"常用优化器总结（一）","path":"/2023/09/29/optimizer1/","content":"什么是优化器 优化器（Optimizer），或者称优化算法，是机器学习或深度学习中用来最小化损失函数的算法。损失函数用来衡量模型预测值和实际值之间的差异，优化器则可以通过一定的策略自动调整模型中的参数值，以使得损失函数的值尽可能的小。 符号约定 以下是本文中使用到的一些符号： θ\\thetaθ: 模型的参数 J(θ)J(\\theta)J(θ): 损失函数 ∇θJ(θ) abla_\\theta J(\\theta)∇θ​J(θ)：参数θ\\thetaθ的梯度 η\\etaη：学习率 x(i)x^{(i)}x(i)：第iii个样本的特征 y(i)y^{(i)}y(i)：第iii个样本的标签 梯度下降 试想我们在山顶上放置一个小球让其向下滚落，则小球每次都会从当前位置最陡的方向向下滚动，最终到达山底。当前位置最陡的方向就是梯度的方向。可以将损失函数也类比为一座山，最开始的时候，我们处在山坡或者山顶，接着我们计算出当前位置的梯度∇θJ(θ) abla_\\theta J(\\theta)∇θ​J(θ)，然后根据梯度∇θJ(θ) abla_\\theta J(\\theta)∇θ​J(θ)更新参数，这相当于小球在最陡的方向滚动了一步，然后重复梯度更新的过程，直至达到损失函数的最小点。 根据计算梯度所使用的样本数量，可以将梯度下降（Gradient Decent）分为批量梯度下降（Batch Gradient Decent，BGD）、随机梯度下降（Stochastic Gradient Descent，SGD）和小批量梯度下降（Mini-batch Gradient Descent，MBGD）。 批量梯度下降 批量梯度下降（Batch Gradient Decent，BGD）每次使用全部的样本计算梯度并更新参数 θ=θ−η∇θJ(θ)\\theta = \\theta - \\eta abla_\\theta J(\\theta) θ=θ−η∇θ​J(θ) 优点 批量梯度下降可以保证收敛到凸函数的最小值，或者非凸函数的极小值点； 缺点 批量梯度下降每次根据全量数据计算梯度，这会导致计算过程非常缓慢，而且如果内存（显存）不足，而数据量又很大时，可能无法一次性加载全部样本计算梯度； 极值和最值 随机梯度下降 随机梯度下降（Stochastic Gradient Descent，SGD）每次只使用一个样本&lt;x(i),y(i)&gt;&lt;x^{(i)}, y^{(i)}&gt;&lt;x(i),y(i)&gt;来计算梯度并更新参数 θ=θ−η∇θJ(θ;x(i);y(i))\\theta = \\theta - \\eta abla_\\theta J(\\theta;x^{(i)};y^{(i)}) θ=θ−η∇θ​J(θ;x(i);y(i)) 优点 每次只使用一个样本更新参数，不会有数据无法加载到内存中的情况； 对于非凸函数，批量梯度下降会收敛到极值点，而由于随机梯度下降每次只使用一个样本计算梯度，相当于只考虑了局部数据的特征，这会使得梯度方向（损失函数的值）的波动比较剧烈，可能会跳出极小值点，从而收敛到最小值点； 缺点 损失函数值波动剧烈，会增长收敛时间； 损失函数值的波动可能会跳出极小值点，收敛到最小值点，也可能导致无法收敛； 小批量梯度下降 小批量梯度下降（Mini-batch Gradient Descent，MBGD）是BGD和SGD的一个折中，它每次使用mmm个样本计算梯度并更新参数 θ=θ−η∇θJ(θ;x(i:i+m);y(i:i+m))\\theta = \\theta - \\eta abla_\\theta J(\\theta;x^{(i:i+m)};y^{(i:i+m)}) θ=θ−η∇θ​J(θ;x(i:i+m);y(i:i+m)) 其中，mmm是一个batch中样本的个数。假设nnn为样本总量，当mmm等于1时，MBGD变为SGD；当mmm等于nnn时，MBGD变为BGD。 优点 相比于批量梯度下降，计算速度更快； 相比于随机梯度下降，收敛过程更加稳定； 缺点 选择合适的学习率比较困难。太小的学习率会导致收敛缓慢，太大的学习率会导致无法收敛到最小值，而是在最小值附近波动，甚至无法收敛； 容易被困在鞍点； 所有的参数使用相同的学习率，对于不同数据集的适应性较差； 注意：上述的BGD和SGD很少被使用，MBGD使用较多。在实际使用中，SGD一般指的是MBGD。在下文中，如果没用明确指出，默认使用SGD表示MBGD。 Momentum Momentum的目的是降低SGD在优化过程中的波动，加快SGD的收敛速度。具体来说，Momentum将梯度更新看作是一个运动的过程，在其中引入了动量的概念，梯度更新的方向就是动量的方向。 Momentum每次在进行梯度更新时，不仅考虑当前梯度的方向，还会考虑之前梯度的方向，这样相当于在参数更新时增加一个惯性，能够在一定程度上减少梯度更新的震荡，使得参数更新的方向更加的稳定。 如上图所示，左边原始的SGD在更新过程中梯度的方向波动较大，而由于Momentum由于考虑了之前梯度的方向，所以波动会相对较小。 举个例子，假设之前梯度的方向是向右下的，而当前梯度的方向是向右上的。如果没有Momentum，则梯度会完全向右上更新。在Momentum中，由于考虑了之前向下的梯度，所以之前向下的梯度和当前向上的梯度会做一个抵消，削弱了向上更新的程度，梯度会更专注于向着最小值方向（向右）前进，从而使得更新过程更加平滑和稳定，收敛速度也会更快。 Momentum可以被形式化为以下公式 vt=βvt−1+(1−β)∇θJ(θ)θ=θ−ηvtv_t = \\beta v_{t-1} + (1 - \\beta) abla_\\theta J(\\theta) \\\\ \\theta = \\theta - \\eta v_t vt​=βvt−1​+(1−β)∇θ​J(θ)θ=θ−ηvt​ 其中 vtv_tvt​是当前时刻的动量（梯度），vt−1v_{t-1}vt−1​是前一时刻的动量，v0v_0v0​初始化为0； β\\betaβ是Momentum的超参数，取值范围为[0, 1]，常见值为0.9； η\\etaη为学习率； 优点： 可以减少梯度更新过程中的震荡，并加速收敛； Adagrad 在SGD或者Momentum中，所有参数的学习率都是一致的。Adagrad的目的是对于不同的参数，可以在训练过程中动态地调整该参数的学习率。具体来说，Adagrad希望对于经常出现的特征，其对应参数的学习率要小一点；而对于不经常出现的特征，其对应参数的学习率要大一点。例如，词向量GloVe是使用Adagrad训练的，对于经常出现的单词，其每一步的词向量的更新比较小；对于不经常出现的单词，其每一步的词向量更新比较大。Adagrad是一种自适应（Adaptive）的优化器，自适应体现在不同的参数可以自动的调节自己的学习率。 为了表示方便，我们使用gtg_tgt​代表参数θ\\thetaθ在ttt时刻的梯度，也就是 gt=∇θtJ(θt)g_t = abla_{\\theta_t} J(\\theta_t) gt​=∇θt​​J(θt​) 则Adagrad可以被形式化为以下公式 θt+1=θt−η∑tgt2+ϵgt\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\sum_t g_t^2 + \\epsilon}} g_t θt+1​=θt​−∑t​gt2​+ϵ​η​gt​ 其中 ∑tgt2\\sum_t g_t^2∑t​gt2​表示参数前ttt个时刻梯度的平方和。如果前ttt个时刻梯度更新的比较多，则该项的值会比较大，学习率η∑tgt2+ϵ\\frac{\\eta}{\\sqrt{\\sum_t g_t^2 + \\epsilon}}∑t​gt2​+ϵ​η​会比较小； ϵ\\epsilonϵ为一个很小的常量，例如10−810^{-8}10−8。该项的目的是防止分母为0； η\\etaη为初始的学习率； Adagrad的优缺点如下 优点 不用手动调节学习率，每个参数都会在训练过程中自适应地调节学习率； 由于会除以梯度的平方和，所以参数的学习率会越来越小，有助于收敛到最值点，而不是在最值点附近左右震荡； 缺点 在计算当前时刻的学习率时，由于会除以之前所有时刻梯度的平方和，所有会导致学习率下降的速度过快，以至于训练后期学习率会非常小，进而造成学习提早停止； Adadelta Adadelta的目的是解决Adagrad中学习率会急剧下降的问题。在Adagrad中，计算当前时刻的学习率时，会除以之前所有时刻梯度的平方和，而在Adadelta中，只会考虑当前时刻前一个固定窗口大小的梯度平方和，但是存储一个滑动窗口大小的梯度平方也是一种比较低效的方法。为了计算更加高效，Adadelta使用一种类似于Momentum的方法当要计算的梯度平方和定义为之前所有时刻梯度平方的指数衰减平均值，如下 E[gt2]=γE[gt−12]+(1−γ)gt2θt+1=θt−ηE[gt2]+ϵgtE[g_t^2] = \\gamma E[g_{t-1}^2] + (1 - \\gamma) g_t^2 \\\\ \\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{E[g_t^2]+\\epsilon}} g_t E[gt2​]=γE[gt−12​]+(1−γ)gt2​θt+1​=θt​−E[gt2​]+ϵ​η​gt​ 其中 E[gt2]E[g_t^2]E[gt2​]为当前时刻ttt之前所有时刻梯度平方的指数衰减平均值，它只跟E[gt−12]E[g_{t-1}^2]E[gt−12​]和gtg_tgt​有关； γ\\gammaγ类似于Momentum中的β\\betaβ，是一个超参数，可以设置为0.9；当设置为0.9时，上面的梯度更新方法等价于另一种优化器：RMSProp； 相比于Adagrad，Adadelta的学习率下降不会特别剧烈。但Adadelta也存在以下问题： 还是需要手动设置一个初始的学习率η\\etaη； 参数的单位和梯度的单位不同，直接相减不是很合理； 为了解决上面两个问题，首先根据参数更新的平方Δθ2\\Delta \\theta^2Δθ2定义另一个衰减平均 E[Δθt2]=γE[Δθt−12]+(1−γ)gt2E[\\Delta \\theta_t^2] = \\gamma E[\\Delta \\theta_{t-1}^2] + (1 - \\gamma) g_t^2 E[Δθt2​]=γE[Δθt−12​]+(1−γ)gt2​ 然后用上式替代初始学习率η\\etaη θt+1=θt−E[Δθt−12]+ϵE[gt2]+ϵgt\\theta_{t+1} = \\theta_t - \\frac{\\sqrt{E[\\Delta \\theta_{t-1}^2]+\\epsilon}}{\\sqrt{E[g_t^2]+\\epsilon}} g_t θt+1​=θt​−E[gt2​]+ϵ​E[Δθt−12​]+ϵ​​gt​ 这样的话，上面的两个问题被解决了。 参数更新的平方不等于梯度的平方，因为在参数更新时还会在梯度前面乘以学习率。 优点 避免了Adagrad中学习率衰减过快的问题； 不用设置初始学习率； Adam Adam（Adaptive Moment Estimation）是另一种自适应的优化器，可以在训练过程中对于不同的参数动态调整其学习率。Adam可以看做是Momentum以及Adadelta的结合，Adam同时计算梯度的指数衰减平均（Momentum）和梯度平方的指数衰减平均（Adadelta），如下 mt=β1mt−1+(1−β1)gtvt=β2vt−1+(1−β2)gt2m_t = \\beta_1 m_{t - 1} + (1 - \\beta_1) g_t \\\\ v_t = \\beta_2 v_{t - 1} + (1 - \\beta_2) g_t^2 mt​=β1​mt−1​+(1−β1​)gt​vt​=β2​vt−1​+(1−β2​)gt2​ mtm_tmt​可以看作是对梯度的一阶矩估计（均值），vtv_tvt​可以看作是对梯度的二阶矩估计（非中心方差）。因为mtm_tmt​和vtv_tvt​是用0初始化的，Adam的作者发现它们的值在后续训练过程中也会偏向于0，特别是在训练刚开始的阶段或者β1\\beta_1β1​和β2\\beta_2β2​都趋近于1时。为了解决这个问题，Adam的作者对mtm_tmt​和vtv_tvt​做了如下的偏差校正 m^t=mt1−β1tv^t=vt1−β2t\\hat{m}_t = \\frac{m_t}{1-\\beta_1^t} \\\\ \\hat{v}_t = \\frac{v_t}{1-\\beta_2^t} m^t​=1−β1t​mt​​v^t​=1−β2t​vt​​ 然后通过校正后的m^t\\hat{m}_tm^t​和v^t\\hat{v}_tv^t​来更新参数 θt+1=θt−ηv^t+ϵm^t\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v}_t}+\\epsilon} \\hat{m}_t θt+1​=θt​−v^t​​+ϵη​m^t​ 在Adam中有3个超参数：计算梯度一阶矩估计（均值）的β1\\beta_1β1​、计算梯度二阶矩估计（非中心方差）的β2\\beta_2β2​以及上式中的ϵ\\epsilonϵ。Adam作者建议将β1\\beta_1β1​设置为0.9，将β2\\beta_2β2​设置为0.999，将ϵ\\epsilonϵ设置为10−810^{-8}10−8。 优点 Adam同时考虑了梯度的一阶矩估计和二阶矩估计，收敛速度会更快； 缺点 需要设置初始学习率η\\etaη； 参考 https://www.ruder.io/optimizing-gradient-descent https://www.cnblogs.com/flix/p/13144064.html https://mingchao.wang/qKUcqJTl/","tags":["深度学习","优化器"]},{"title":"国庆九日记","path":"/2023/09/28/nations-day/","content":"国庆节是下半年最长的节日，今年因为国庆节和中秋节重叠，所以一共有8天的假期。当然，假期结束后也会有2天的调休。想用这篇博客记录下我在这个假期里的生活。 2023/09/28 今天是我的假期的第一天。实际上，法定假期从明天才开始，因为明天是中秋节，所以我请了一天假提前走了。由于我最近很累，所以选择了回家休息。因为头天晚上睡不着，而且早上也起不来，所以一直拖到火车开前1个小时才出发，还好路上比较顺利，及时赶上了火车。可能是因为我提前走一天的原因，地铁和火车站的人流量是正常的水平，没有人特别多的感觉。在火车上，由于有人外放加上小孩吵闹的缘故，我基本上没有睡觉。到家后觉得挺累的，毕竟坐了一天，也没怎么睡觉和吃东西。刚把饭吃了，打算今天早点睡。 给自己的假期定一个基调： 早睡早起 少玩手机 增强自律 2023/09/29 今天是假期的第二天，也是中秋节。夜里醒了一次，听到外面再下雨，很快又睡过去了。早上8点醒来之后，到中午吃饭这段时间我在做什么，我已经没有了印象（大概就是啥都没做）。下午2点睡午觉，睡到了4点多，起来写了一篇博客但没有写完。然后就是吃晚饭，再就是到现在晚上11点。今天给我的感觉就是时间真的过得很快，没有什么感觉一天就过去了。最后，祝自己、家人、大家中秋快乐。 2023/09/30 今天是假期的第三天，也是九月的最后一天。今天是一个多云天，早上9点起床，上午继续写昨天没写完的博客，写了一半吃了中饭。吃完中饭后，睡了一个小时的午觉，下午把昨天没完成的博客写完了。回来前有一个刷题的计划，但回到家的这两天没怎么刷，明天需要刷起来了，不然假期就要结束了。算了，待会就开始刷吧，刷一题也比不刷强，不然明天估计又要拖延。 2023/10/01 今天是假期的第四天，是国庆节，也是十月的第一天。今天和前几天差不多，但没有写其他的博客，刷了一些题，但不是很多。晚上7点左右开始下小雨，到现在晚上11点雨基本停了。晚上看了亚运会乒乓球女单决赛，孙颖莎大比分落后追分再赢下比赛令人印象深刻；田径女子100米栏决赛告诉我们做事不要急躁。打算睡觉了，在家不熬夜了。明天还是要多刷一些题。 2023/10/02 今天是假期的第五天，假期已经过半。今天主要是刷了一些题，在外面看了一会雨。晚上看了亚运会乒乓球男单决赛，昨天看了乒乓球女单的决赛，这两场比赛看完我的感受是：一时的落后不代表一直会落后，一时的领先也不代表一直会领先，不到最后，谁也不知道结果会如何。在落后时稳住心态，在领先时不骄不躁，一步一个脚印，才能取得最后的成功。共勉。 2023/10/03 今天是假期的第六天，离出发的日子越来越近了。今天依旧是刷了一些题，感觉回来之前给自己定下的目标完成的一般，剩下几天可以再看下。今天晚上看了亚运会，发现田径里的三级跳观赏性挺高的，以前没怎么注意过。印象深刻的是男子4×100米接力决赛，中国队最后一棒在最后50米左右反超拿下金牌，还是要对自己有信心。最后，分享两张拍摄于今天的照片 上午天空 晚霞 2023/10/04 今天是假期的第七天，离出发还剩一个周末。今天晚上看了亚运会男子篮球半决赛中国对菲律宾，中国队基本上领先了一整场，最高领先分差达到了20分，但是在最后23秒被反超1分，最后输掉了比赛。这告诉我们不到最后一刻，不要放松警惕。如果没有退路，索性放手一搏。最近看了几场亚运会的比赛，发现解说的表达能力都非常强。不像主持人有提前写好的稿子，解说需要实时地对场上的情况进行快速准确地分析和描述，这就很考验表达能力了。而且解说的表达都很简练和流畅，前一句和下一句之间有关联，很少有重复的废话，值得自己学习。 2023/10/05 今天是假期的第八天，倒计时一天。其实回去的火车票还没有候补到，看下明天能不能候补到吧。其他的跟前几天差不多，不再赘述。 2023/10/06 今天是假期的第九天，也是在家的最后一天。我的10/07的返程车票候补了好多天都没有候补到，本来计划候补不到的话就8号走，然后在今天下午候补到了，所以就明天走吧。在家的时间真的很快，这个假期下了几场雨，有时睡前下雨或者夜里醒来听见外面在下雨，心里会很踏实，然后很快就会睡过去。总的来说，在家熬夜还是要比工作时要少一点的。而且，基本每天都是睡到自然醒。 总结 这次应该是我第一次尝试用文字把整个假期的生活记录下来，虽然内容不是很丰富且偏流水账，但还是给自己留下了关于这个假期的具象化的记忆。这次假期也像是一个缓冲，把我从假期前的生活中解救出来，让我喘了一口气。现在假期正式结束了，明天也要去上班了。希望自己保持平和的心态，继续向前吧。","tags":["生活"]},{"title":"使用Github Actions实现Hexo博客的自动部署","path":"/2023/08/19/hexo-with-actions/","content":"什么是Github Actions 简单来说，Actions是一个工作流（Workflow），可以根据设定的触发条件，执行一连串预设的操作，从而实现工作的自动执行。具体可以参考这篇文章。在写博客场景下，我们希望有这样的一个Actions，当我们将写好的博客推到Github时，Actions能帮我们自动执行hexo g、hexo d这些操作。这样我们在写完博客后，push到Github上就行了，其余的博客编译，部署都是自动的，大大降低了复杂度。 为了实现上面的功能，我们首先需要创建两个仓库：源码库和公开库。 两个仓库 源码库 可以使用 hexo init blog来创建一个名为blog的源码库，源码库用来存放博客源文件（markdown文件）。需要将本地创建的源码库push到Github上。推到Github上后，源码库可以设为私有库。 公开库 如果我们在源码库里执行hexo g会产生一个public文件夹，这个文件夹包含了编译后的静态网页文件，也是公开库的内容，在Github上对应仓库$&#123;username&#125;.github.io。 整体的流程是：本地写博客-&gt;push到源码库-&gt;命中Actions的触发条件，自动执行编译-&gt;自动将编译得到的public文件夹内容push到公开库-&gt;完成。 Secrets Secrets可以理解为Actions工作的一个凭证，配置文件中的Secrets和在Github上设置的Secrets一致时，Actions中的相关步骤才能正常执行。在Github上创建Secrets的方法是：头像-&gt;Settings-&gt;Developer Settings-&gt;Personal Access Tokens-&gt;Tokens(classic)-&gt;Generate new token-&gt;选择workflow，如下所示 然后拷贝生成的token，打开Github上的源码库-&gt;Settings-&gt;Secrets and variables创建一个名为PERSONAL_TOKEN的Secrets，如下图 配置Actions 这一步我们定义Actions在什么时候触发，触发后执行什么操作。在源码库下新建文件.github/workflows/auto-deploy.yml，例如我的内容如下： 1234567891011121314151617181920212223242526272829303132333435363738name: auto deployon: workflow_dispatch: push: # 触发的条件为push操作，如果向这个仓库push，就是执行下面的jobsjobs: build: runs-on: ubuntu-latest # 运行环境为最新版 Ubuntu name: auto deploy steps: # 1. 获取源码 - name: Checkout uses: actions/checkout@v3 # 使用 actions/checkout@v3 with: # 条件 submodules: true # Checkout private submodules(themes or something else). 当有子模块时切换分支？ # 2. 配置环境 - name: Setup Node.js 18.12.x uses: actions/setup-node@master with: node-version: &quot;18.12.x&quot; # 3. 生成静态文件 - name: Generate Public Files run: | npm i npm install hexo-cli -g hexo clean &amp;&amp; hexo generate # 4. 部署到 GitHub 仓库（可选） - name: Deploy to GitHub Pages uses: peaceiris/actions-gh-pages@v3 with: personal_token: $&#123;&#123; secrets.PERSONAL_TOKEN &#125;&#125; # 这个就是配置的secrets external_repository: $&#123;username&#125;/$&#123;username&#125;.github.io # 需要修改为自己的用户名 publish_branch: gh-pages # 推到了公开库的gh-pages分支 publish_dir: ./public commit_message: $&#123;&#123; github.event.head_commit.message &#125;&#125; user_name: &#x27;$&#123;username&#125;&#x27; # 需要修改为自己的用户名 user_email: &#x27;$&#123;username&#125;@exampe.com&#x27; # 需要修改为自己的邮箱 上面的文件定义了一个完整的Actions，最终将编译好的博客push到公开库的gh-pages分支。需要注意的是，如果公开库设定的展示分支不是gh-pages，需要修改为gh-pages。或者修改上面的配置，将publish_branch改为自己的分支。 至此，Actions就被配置好了。我们在源码库写完博客后，git add、git commit、git push到Github上就会自动部署到Github Pages，省去了搭建Hexo环境的步骤，非常方便。而且，如果我们想在别的电脑上写博客，git clone源码库到本地修改即可，也可以使用Github提供的Codespaces在浏览器里修改后执行push，多端修改也很方便。 参考 零成本！无需服务器也能搭建自己的博客网站，支持CI/CD！ 配置Github Action实现自动发布 利用 GitHub Actions 自动部署 Hexo 博客","tags":["教程, hexo"]},{"title":"关于","path":"/about/index.html","content":"游山西村陆游莫笑农家腊酒浑，丰年留客足鸡豚。山重水复疑无路，柳暗花明又一村。箫鼓追随春社近，衣冠简朴古风存。从今若许闲乘月，拄杖无时夜叩门。诗词节选"}]